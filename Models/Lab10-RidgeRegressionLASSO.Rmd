---
title: "Lab10-Ridge Regression and LASSO"
author: "DuraiSundaramoorthi"
output: pdf_document
---

##6.6.1 Ridge Regression

```
x = model.matrix(Salary~.,Hitters)[,-1]

x

y = Hitters$Salary

library(glmnet)

grid = 10^seq(10,-2,length=100)

grid

ridge.mod = glmnet(x,y,alpha=0,lambda=grid)

dim(coef(ridge.mod))

ridge.mod$lambda[50]

coef(ridge.mod)[,50]

ridge.mod$lambda[60]

coef(ridge.mod)[,60]

predict(ridge.mod,s= 50,type ="coefficients")[1:20,]

set.seed(1)

train = sample(1:nrow(x), nrow(x)/2) ##default replace = FALSE

test = (-train)

y.test = y[test]

ridge.mod = glmnet(x[train,],y[train],alpha = 0,lambda = grid,thresh = 1e-12)

ridge.pred=predict(ridge.mod,s=4,newx=x[test,])

mean((ridge.pred-y.test)^2)

mean((mean(y[train])-y.test)^2) ## Null Model

ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,]) 

mean((ridge.pred-y.test)^2) ## Ridge Regression with only intercept

ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact = T)

mean((ridge.pred -y.test)^2)

lm(y~x, subset=train)

predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]


##Cross-validation

set.seed(1)

cv.out = cv.glmnet(x[train,],y[train], alpha=0)

plot(cv.out)

bestlam = cv.out$lambda.min

bestlam

ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])

mean((ridge.pred-y.test)^2)

out = glmnet(x,y,alpha=0)

predict(out,type="coefficients",s=bestlam)[1:20,]
```

## The Lasso

```

lasso.mod = glmnet(x[train,],y[train],alpha = 1,lambda = grid)

plot(lasso.mod)

set.seed(1)

cv.out = cv.glmnet(x[train,],y[train],alpha=1)

plot(cv.out)

bestlam = cv.out$lambda.min

lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])

mean((lasso.pred-y.test)^2)

out=glmnet(x,y,alpha=1,lambda=grid)

lasso.coef = predict(out,type="coefficients",s=bestlam)[1:20,]

lasso.coef
```
